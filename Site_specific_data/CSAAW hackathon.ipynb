{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "CSAAW Hackathon\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn import preprocessing \n",
    "import glob\n",
    "\n",
    "\n",
    "NormalizationFlag = 2 # 0 is normalizing by norm, 1 is scale it, 2 is make it in between [0,1]\n",
    "dataset_list = []\n",
    "for files in glob.glob(\"*.csv\"):\n",
    "    dataset_list.append(files)\n",
    "    #print files \n",
    "    \n",
    "N = len(dataset_list)\n",
    "for site in range(0,N):\n",
    "    \n",
    "    dataset_file = dataset_list[site]\n",
    "    dataset = genfromtxt(dataset_file, delimiter=',')\n",
    "    \n",
    "    if len(dataset.shape) == 2:\n",
    "        datasetX = dataset[:,:-1]\n",
    "        datasetID = dataset[:,-1]\n",
    "    else: \n",
    "        dataset = dataset[np.newaxis,:]\n",
    "        datasetX = dataset[:,:-1]\n",
    "        datasetID = dataset[:,-1]\n",
    "    \n",
    "    if NormalizationFlag == 0:\n",
    "        dataset_normalized = preprocessing.normalize(datasetX, norm='l2')\n",
    "    elif NormalizationFlag == 1:\n",
    "        dataset_normalized = preprocessing.scale(datasetX)\n",
    "    elif NormalizationFlag == 2:\n",
    "        min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "        dataset_normalized = min_max_scaler.fit_transform(datasetX)\n",
    "        \n",
    "    dataset_site = 'dataset' + str(site)\n",
    "    exec (dataset_site + \" = dataset_normalized\")\n",
    "    \n",
    "\n",
    "S = np.zeros([N,N])\n",
    "for ii in range(0,N):\n",
    "    dataset_ii = 'dataset' + str(ii)\n",
    "    for jj in range(0,N):\n",
    "        dataset_jj = 'dataset' + str(jj)\n",
    "        \n",
    "        ## (??) Kernelize This \n",
    "        M = euclidean_distances(eval(dataset_ii),eval(dataset_jj)) \n",
    "        #print M\n",
    "        S[ii,jj] = np.linalg.norm(M,ord = 'fro')/(float(M.shape[0])*float(M.shape[1]))\n",
    "\n",
    "\n",
    "#print S\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.random.rand(10,5)\n",
    "b = np."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
